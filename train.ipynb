{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "conda environment \n",
    "\n",
    "train/validate/test\n",
    "\n",
    "estimated long axis images (png file)\n",
    "\n",
    "Deep learning models\n",
    "1. 4 layer Conv BatchNorm ReLu CNN model\n",
    "2. Transfer learning with EfficientNet-B0 pretrained net \n",
    "\n",
    "'''\n",
    "\n",
    "# import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import imageio\n",
    "import skimage\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import PyQt5\n",
    "%matplotlib qt\n",
    "\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "\n",
    "from skimage import io, exposure\n",
    "from shutil import copyfile, copytree\n",
    "from scipy import ndimage\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, BatchNormalization, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import EfficientNetB0, MobileNet, NASNetMobile, ResNet50, VGG16\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.utils import class_weight  \n",
    "from dl_func_la import gen_cnn_model, grayscale_to_rgb, resize_to_224, resize_to_96\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "gpu_no = '/gpu:0'\n",
    "\n",
    "base_dir   = r'D:\\python\\yoonckim\\longaxis'\n",
    "excel_file = r'label_motion_10_bmcR1.xlsx'\n",
    "dir_kfold  = r'data\\CAT_KAG_kfold'\n",
    "\n",
    "\n",
    "''' \n",
    " model_name:\n",
    " '4_layer': CBR CNN with four layers \n",
    " 'EfficientNetB0': transfer learning (EfficientNetB0)\n",
    "'''\n",
    "# model_name = 'CustomCBR'\n",
    "# model_name = 'EfficientNetB0'\n",
    "# model_name = 'MobileNet'\n",
    "# model_name = 'NASNetMobile'\n",
    "# model_name = 'ResNet50'\n",
    "model_name = 'VGG16'\n",
    "\n",
    "# augment_method = 'noAugment'\n",
    "augment_method = 'flipLR'  # 'flipLR' only\n",
    "\n",
    "model_path = os.path.join('data/CAT_KAG_model1', model_name, augment_method)\n",
    "\n",
    "fname1 = os.path.join(base_dir, excel_file)\n",
    "df1 = pd.read_excel(fname1, sheet_name='Sheet1', index_col=None, engine='openpyxl')\n",
    "print(df1['ID'].size)\n",
    "df2 = df1[df1['image_interpretable'] == 'interpretable'] \n",
    "print(df2['ID'].size)\n",
    "\n",
    "a = list(df2.columns)\n",
    "col_list = a\n",
    "print(col_list)\n",
    "\n",
    "id_list = list(df2['ID'])\n",
    "png_fname_list = list(df2['png_fname'])\n",
    "isTrain_list = list(df2['isTrain'])\n",
    "motion_flag_list = list(df2['motion_flag'])\n",
    "    \n",
    "# print(motion_flag_list)\n",
    "png_train_dir = r'data\\CAT_KAG\\train'\n",
    "\n",
    "nfold = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if False:\n",
    "\n",
    "    png_train_dir_CAT = r'data\\CAT\\train';\n",
    "    png_train_dir_KAG = r'data\\KAG_2ndAnnual\\png\\train';\n",
    "    \n",
    "    png_test_dir_CAT  = r'data\\CAT\\test'\n",
    "    png_test_dir_KAG  = r'data\\KAG_2ndAnnual\\png\\test';\n",
    "\n",
    "    png_new_train_dir = r'data\\CAT_KAG\\train'\n",
    "    png_new_test_dir  = r'data\\CAT_KAG\\test'\n",
    "    \n",
    "    isShuffling = False\n",
    "    \n",
    "    if isShuffling==True:\n",
    "        list_dir1 = glob(png_train_dir + '\\\\DET0*')\n",
    "        list_dir2 = glob(png_test_dir + '\\\\DET0*')\n",
    "        list_dir3 = list_dir1 + list_dir2\n",
    "        # print(list_dir3)\n",
    "        list_dir3_rand = copy.copy(list_dir3)\n",
    "        random.seed(870723)\n",
    "        random.shuffle(list_dir3_rand)\n",
    "        # print(list_dir3_rand)\n",
    "        print(len(list_dir3_rand))\n",
    "        ntrain = np.round(0.7 * len(list_dir3_rand)).astype(int)\n",
    "        print(ntrain)\n",
    "        list_dir_train = list_dir3_rand[:ntrain]\n",
    "        list_dir_test = list_dir3_rand[ntrain:]\n",
    "    else:\n",
    "        list_dir1 = glob(png_train_dir_CAT + '\\\\DET0*')\n",
    "        list_dir2 = glob(png_train_dir_KAG + '\\\\*')\n",
    "        list_dir_train = list_dir1 + list_dir2\n",
    "        \n",
    "        list_dir1 = glob(png_test_dir_CAT + '\\\\DET0*')\n",
    "        list_dir2 = glob(png_test_dir_KAG + '\\\\*')\n",
    "        list_dir_test = list_dir1 + list_dir2       \n",
    "        \n",
    "    for jj, dir1 in enumerate(list_dir_train):\n",
    "        dir_, id_folder = os.path.split(dir1)\n",
    "        subj_png_dir = os.path.join(png_new_train_dir, id_folder)\n",
    "        copytree(dir1, subj_png_dir)  \n",
    "    \n",
    "    for jj, dir1 in enumerate(list_dir_test):\n",
    "        dir_, id_folder = os.path.split(dir1)\n",
    "        subj_png_dir = os.path.join(png_new_test_dir, id_folder)\n",
    "        copytree(dir1, subj_png_dir)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "create directories of five-folds data\n",
    "'''\n",
    "\n",
    "if False:\n",
    "    list_dirs = glob(png_train_dir + '\\\\*')\n",
    "    nsubj = len(list_dirs)\n",
    "    print(f'nsubj = {nsubj}')\n",
    "\n",
    "    list_dirs_rand = copy.copy(list_dirs)\n",
    "    print(list_dirs)\n",
    "    random.seed(870723)\n",
    "    random.shuffle(list_dirs_rand)\n",
    "    print(list_dirs_rand)\n",
    "\n",
    "    fold_indices = []\n",
    "    dir_fold = []\n",
    "    nchunk = int(nsubj/nfold)\n",
    "\n",
    "    for k in range(nfold):\n",
    "        indices = np.arange(k*nchunk, (k+1)*nchunk)\n",
    "        fold_indices.append(indices)\n",
    "\n",
    "    # print(fold_indices[4])\n",
    "    # print(0 in fold_indices[1])\n",
    "    # print(list_dirs_rand[0])\n",
    "\n",
    "    dir_, id_ = os.path.split(list_dirs_rand[0])\n",
    "    # print(dir_)\n",
    "\n",
    "    for kk, dir_name in enumerate(list_dirs_rand):\n",
    "        for fold_group in range(nfold):\n",
    "            if kk in fold_indices[fold_group]:\n",
    "                dir_, id_folder = os.path.split(dir_name)\n",
    "                subj_png_dir2 =  os.path.join(dir_kfold, 'fold'+str(fold_group+1), id_folder)\n",
    "                dir_name2 = os.path.join(dir_name, 'estLA')\n",
    "                copytree(dir_name2, subj_png_dir2)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' \n",
    "functions\n",
    "\n",
    "'''\n",
    "\n",
    "def find_index_string(png_fname_list1, substring):\n",
    "    \n",
    "    for ind, fname_ in enumerate(png_fname_list1):\n",
    "        if substring in fname_:\n",
    "            index = ind\n",
    "            break\n",
    "        else:\n",
    "            index = -1000 # in case not found\n",
    "    \n",
    "    return index\n",
    "\n",
    "def scale_color(pixel_array):\n",
    "    p2, p98 = np.percentile(pixel_array, (2, 98))\n",
    "    \n",
    "    return exposure.rescale_intensity(pixel_array, in_range=(p2, p98))\n",
    "\n",
    "def thresh1(img):\n",
    "    img_th = scale_color(img)\n",
    "    \n",
    "    return img_th\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_num = 2   \n",
    "\n",
    "history_dict = {}\n",
    "\n",
    "val_fold_list = [1, 2, 3, 4, 5]\n",
    "# val_fold_list = [3, 4, 5]\n",
    "# val_fold_list = [5]\n",
    "\n",
    "for _, val_f in enumerate(val_fold_list):\n",
    "\n",
    "    if   val_f==1:        train_fold = [2,3,4,5]         \n",
    "    elif val_f==2:        train_fold = [1,3,4,5]         \n",
    "    elif val_f==3:        train_fold = [1,2,4,5]         \n",
    "    elif val_f==4:        train_fold = [1,2,3,5]         \n",
    "    elif val_f==5:        train_fold = [1,2,3,4]         \n",
    "    val_fold = [val_f]\n",
    "    \n",
    "    print(f'training data: val fold = {val_f}')\n",
    "    \n",
    "    train_img    = list()\n",
    "    train_motion = list()\n",
    "\n",
    "    val_img      = list()\n",
    "    val_motion   = list()\n",
    "\n",
    "    for jj, value in enumerate(train_fold):\n",
    "        dir_3 = os.path.join(dir_kfold, 'fold'+str(value))\n",
    "        dir_id = glob(dir_3 + '\\\\*')\n",
    "\n",
    "        for kk, id_ in enumerate(dir_id):\n",
    "            list_png = glob(id_ + '\\\\*.png')       \n",
    "            \n",
    "            for ll, fname_png in enumerate(list_png):\n",
    "                dir_, fname_ = os.path.split(fname_png)\n",
    "                img = imageio.imread(fname_png) \n",
    "                img1 = skimage.transform.resize(img, (96, 256), anti_aliasing=True, preserve_range=False)\n",
    "                \n",
    "                # crop and normalize\n",
    "                img2 = img1[:, (128-96):(128+96)]\n",
    "                sh = 10 # pixel\n",
    "                img2m20t = img1[:, (128-sh-96):(128-sh+96)]\n",
    "                img2p20t = img1[:, (128+sh-96):(128+sh+96)]\n",
    "                \n",
    "                img2 = img2/np.max(img2)\n",
    "                ang = 5 # degree\n",
    "                img2m10r = ndimage.rotate(img2, -ang, reshape=False)\n",
    "                img2p10r = ndimage.rotate(img2,  ang, reshape=False)\n",
    "                \n",
    "                img2m20t = img2m20t/np.max(img2m20t)\n",
    "                img2p20t = img2p20t/np.max(img2p20t)               \n",
    "                \n",
    "                ind = find_index_string(png_fname_list, fname_)\n",
    "                if ind == -1000:\n",
    "                    print(f'{fname_} is outlier. continue')\n",
    "                    continue\n",
    "\n",
    "                if 'presen' in motion_flag_list[ind]: \n",
    "                    motion_eLA = 1\n",
    "                elif 'absen' in motion_flag_list[ind]: \n",
    "                    motion_eLA = 0\n",
    "                else: quit()    \n",
    "                \n",
    "                if augment_method == 'aug_method3':\n",
    "                    #print(f'{augment_method} performed!')\n",
    "                    train_img.append(img2);                  train_motion.append(motion_eLA)\n",
    "                    train_img.append(np.fliplr(img2));       train_motion.append(motion_eLA)\n",
    "                    train_img.append(img2m10r);              train_motion.append(motion_eLA)\n",
    "                    train_img.append(np.fliplr(img2m10r));   train_motion.append(motion_eLA)\n",
    "                    train_img.append(img2p10r);              train_motion.append(motion_eLA)\n",
    "                    train_img.append(np.fliplr(img2p10r));   train_motion.append(motion_eLA)\n",
    "                    train_img.append(img2m20t);              train_motion.append(motion_eLA)\n",
    "                    train_img.append(np.fliplr(img2m20t));   train_motion.append(motion_eLA)\n",
    "                    train_img.append(img2p20t);              train_motion.append(motion_eLA)\n",
    "                    train_img.append(np.fliplr(img2p20t));   train_motion.append(motion_eLA)\n",
    "                    \n",
    "                    if jj==0 and kk==1 and ll==0 and False:\n",
    "                        plt.figure(figsize=(12, 5))\n",
    "                        plt.subplot(251)\n",
    "                        plt.imshow(img2, cmap='gray'); plt.title('img1: img1'); plt.axis('off')\n",
    "                        plt.subplot(252)\n",
    "                        plt.imshow(img2m10r, cmap='gray'); plt.title('img2: -10-deg rotate'); plt.axis('off')\n",
    "                        plt.subplot(253)\n",
    "                        plt.imshow(img2p10r, cmap='gray'); plt.title('img3: +10-deg rotate'); plt.axis('off')\n",
    "                        plt.subplot(254)\n",
    "                        plt.imshow(img2m20t, cmap='gray'); plt.title('img4: -20 pix translate'); plt.axis('off')\n",
    "                        plt.subplot(255)\n",
    "                        plt.imshow(img2p20t, cmap='gray'); plt.title('img5: +20 pix translate'); plt.axis('off')\n",
    "                        \n",
    "                        plt.subplot(256)\n",
    "                        plt.imshow(np.fliplr(img2), cmap='gray'); plt.title('img6: fliplr of img1'); plt.axis('off')\n",
    "                        plt.subplot(257)\n",
    "                        plt.imshow(np.fliplr(img2m10r), cmap='gray'); plt.title('img7: fliplr of img2'); plt.axis('off')\n",
    "                        plt.subplot(258)\n",
    "                        plt.imshow(np.fliplr(img2p10r), cmap='gray'); plt.title('img8: fliplr of img3'); plt.axis('off')\n",
    "                        plt.subplot(259)\n",
    "                        plt.imshow(np.fliplr(img2m20t), cmap='gray'); plt.title('img9: fliplr of img4'); plt.axis('off')\n",
    "                        plt.subplot(2,5,10)\n",
    "                        plt.imshow(np.fliplr(img2p20t), cmap='gray'); plt.title('img10: fliplr of img5'); plt.axis('off')\n",
    "                        \n",
    "                        plt.show()\n",
    "                    \n",
    "                elif augment_method == 'aug_method2':\n",
    "                    #print(f'{augment_method} performed!')\n",
    "                    train_img.append(img2);            train_motion.append(motion_eLA)\n",
    "                    train_img.append(img2m10r);        train_motion.append(motion_eLA)\n",
    "                    train_img.append(img2p10r);        train_motion.append(motion_eLA)\n",
    "                    train_img.append(img2m20t);        train_motion.append(motion_eLA)\n",
    "                    train_img.append(img2p20t);        train_motion.append(motion_eLA)\n",
    "                    \n",
    "                elif augment_method == 'flipLR':\n",
    "                    train_img.append(img2);            train_motion.append(motion_eLA)\n",
    "                    train_img.append(np.fliplr(img2)); train_motion.append(motion_eLA)\n",
    "                    \n",
    "                elif augment_method == 'noAugment':  \n",
    "                    #print('No Augment')\n",
    "                    train_img.append(img2);            train_motion.append(motion_eLA)\n",
    "                \n",
    "    print(len(train_img), len(train_motion))\n",
    "    \n",
    "    for jj, value in enumerate(val_fold):\n",
    "        dir_3 = os.path.join(dir_kfold, 'fold'+str(value))\n",
    "        dir_id = glob(dir_3 + '\\\\*')\n",
    "        print(len(dir_id))\n",
    "\n",
    "        for kk, id_ in enumerate(dir_id):\n",
    "            list_png = glob(id_+'\\\\*.png')       \n",
    "\n",
    "            for ll, fname_png in enumerate(list_png):\n",
    "                dir_, fname_ = os.path.split(fname_png)\n",
    "                img = imageio.imread(fname_png)\n",
    "                img2 = skimage.transform.resize(img, (96, 256), anti_aliasing=True, preserve_range=False)\n",
    "                \n",
    "                img2 = img2[:, (128-96):(128+96)]\n",
    "                img2 = img2/np.max(img2)\n",
    "                \n",
    "                ind = find_index_string(png_fname_list, fname_)\n",
    "                if ind == -1000:\n",
    "                    print(f'{fname_} is outlier. continue')\n",
    "                    continue                \n",
    "                \n",
    "                if 'presen' in motion_flag_list[ind]: \n",
    "                    motion_eLA = 1\n",
    "                elif 'absen' in motion_flag_list[ind]: \n",
    "                    motion_eLA = 0\n",
    "                else: quit()\n",
    "                \n",
    "                val_img.append(img2)\n",
    "                val_motion.append(motion_eLA)\n",
    "\n",
    "    print(len(val_img), len(val_motion))\n",
    "\n",
    "    X_train = np.stack(train_img, axis=0)\n",
    "    y_train = np.stack(train_motion, axis=0)\n",
    "\n",
    "    X_val = np.stack(val_img, axis=0)\n",
    "    y_val = np.stack(val_motion, axis=0)\n",
    "\n",
    "    X_train_ = grayscale_to_rgb(X_train)\n",
    "    X_val_ = grayscale_to_rgb(X_val)\n",
    "\n",
    "    sess2 = tf.compat.v1.Session()\n",
    "    with sess2.as_default():\n",
    "        X_train = X_train_.numpy()\n",
    "        X_val = X_val_.numpy()\n",
    "\n",
    "    print(f'X_train shape: {X_train.shape}, X_val shape: {X_val.shape}')\n",
    "        \n",
    "    #\n",
    "    # check class imbalance\n",
    "    #\n",
    "\n",
    "    #### inter-breath-hold motion detection\n",
    "    print('inter-breath-hold motion detection')\n",
    "    pos = np.where(y_train==1)[0];     n_pos = len(pos)\n",
    "    print(f'train     : motion(+) group: # of images = {n_pos}')\n",
    "    \n",
    "    neg = np.where(y_train==0)[0];    n_neg = len(neg)\n",
    "    print(f'train     : motion(-) group: # of images = {n_neg}')\n",
    "    \n",
    "    pos = np.where(y_val==1)[0];    n_pos = len(pos)\n",
    "    print(f'validation: motion(+) group: # of images = {n_pos}')\n",
    "    \n",
    "    neg = np.where(y_val==0)[0];    n_neg = len(neg)\n",
    "    print(f'validation: motion(-) group: # of images = {n_neg}')\n",
    "\n",
    "    input_shape_TLmodel = '224'\n",
    "    \n",
    "    if model_name == 'CustomCBR':\n",
    "    \n",
    "        n_filter = 16; \n",
    "        kernel1 = (3, 3); \n",
    "        padding1 = 'same' \n",
    "        strides1 = (1, 1)\n",
    "        input_shape = (96, 192, 3)\n",
    "        pool_size1 = (2, 2)\n",
    "        pool_size2 = (2, 2)\n",
    "\n",
    "        learning_rate = 0.00001    #0.000001  #0.000001  #0.00001  #0.000001\n",
    "        batch_size = 4\n",
    "        n_epochs = 50 # 200 #50 #100 #150\n",
    "\n",
    "        with K.tf.device(gpu_no):\n",
    "\n",
    "            model = Sequential()\n",
    "            model.add(Conv2D(filters=n_filter, kernel_size=kernel1, padding=padding1, strides=strides1, input_shape=input_shape))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Activation(\"relu\"))\n",
    "            model.add(MaxPooling2D(pool_size=pool_size2) )\n",
    "\n",
    "            model.add(Conv2D(filters=2*n_filter, kernel_size=kernel1, padding=padding1, strides=strides1) )\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Activation(\"relu\"))\n",
    "            model.add(MaxPooling2D(pool_size=pool_size1) )         \n",
    "\n",
    "            model.add(Conv2D(filters=4*n_filter, kernel_size=kernel1, padding=padding1, strides=strides1))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Activation(\"relu\"))\n",
    "            model.add(MaxPooling2D(pool_size=pool_size1)  )   \n",
    "\n",
    "            model.add(Conv2D(filters=8*n_filter, kernel_size=kernel1, padding=padding1, strides=strides1))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Activation(\"relu\"))\n",
    "            model.add(MaxPooling2D(pool_size=pool_size1)  )\n",
    "\n",
    "            model.add(Flatten()) \n",
    "            model.add(Dense(64))\n",
    "            model.add(Activation(\"relu\"))\n",
    "\n",
    "            model.add(Dropout(0.5))\n",
    "\n",
    "            model.add(Dense(class_num, activation='sigmoid'))\n",
    "            model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "        # prepare data for CNN\n",
    "        if False:\n",
    "            for ind in range(2, y_train.shape[0], 30):    \n",
    "                label = y_train[ind]\n",
    "                plt.figure(figsize=(9, 3))\n",
    "                img1 = X_train[ind, :, :, 0]\n",
    "                plt.imshow(img1, cmap='gray')\n",
    "\n",
    "                if class_num == 2:\n",
    "                    plt.title(f'label={label}: motion=1, no motion=0')\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "    elif model_name == 'EfficientNetB0':\n",
    "        \n",
    "        input_shape_TLmodel = '224'\n",
    "                        \n",
    "        # input_shape = (96, 128, 3) => (224, 224, 3) shape conversion\n",
    "        if input_shape_TLmodel == '224':\n",
    "            learning_rate = 0.0001  # 0.0001\n",
    "            input_shape = (224, 224, 3)\n",
    "            inputs = Input(shape=input_shape)\n",
    "                \n",
    "            X_train2 = resize_to_224(X_train) \n",
    "            X_val2 = resize_to_224(X_val)\n",
    "        \n",
    "        elif input_shape_TLmodel == '96':\n",
    "            learning_rate = 0.0005  # 0.0001\n",
    "            input_shape = (96, 128, 3)\n",
    "            inputs = Input(shape=input_shape)\n",
    "            \n",
    "            X_train2 = resize_to_96(X_train)\n",
    "            X_val2 = resize_to_96(X_val)\n",
    "            \n",
    "        batch_size = 2  \n",
    "        n_epochs = 50\n",
    "        \n",
    "        x = inputs\n",
    "        \n",
    "        with K.tf.device(gpu_no):\n",
    "            model = EfficientNetB0(include_top=False, input_tensor=x, weights=\"imagenet\")\n",
    "            # Freeze the pretrained weights\n",
    "            model.trainable = False\n",
    "\n",
    "            # Rebuild top\n",
    "            x = GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "            x = BatchNormalization()(x)\n",
    "\n",
    "            top_dropout_rate = 0.2\n",
    "            x = Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "            outputs = Dense(class_num, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "            # Compile\n",
    "            model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
    "            model.compile(optimizer=Adam(learning_rate=learning_rate), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "            #epochs = 50  # @param {type: \"slider\", min:8, max:80}\n",
    "            #history1 = model.fit(ds_train, epochs=epochs, validation_data=ds_test, verbose=2)\n",
    "            #plot_hist(hist)    \n",
    "        \n",
    "    elif model_name == 'MobileNet':\n",
    "        \n",
    "        input_shape_TLmodel = '224'\n",
    "                \n",
    "        if input_shape_TLmodel == '224':\n",
    "            learning_rate = 0.0001  # 0.0001\n",
    "            input_shape = (224, 224, 3)\n",
    "            inputs = Input(shape=input_shape)\n",
    "                \n",
    "            X_train2 = resize_to_224(X_train) \n",
    "            X_val2 = resize_to_224(X_val)\n",
    "        \n",
    "        batch_size = 2  \n",
    "        n_epochs = 50\n",
    "        \n",
    "        x = inputs\n",
    "        \n",
    "        with K.tf.device(gpu_no):\n",
    "            model = MobileNet(include_top=False, input_tensor=x, weights=\"imagenet\")\n",
    "            # Freeze the pretrained weights\n",
    "            model.trainable = False\n",
    "\n",
    "            # Rebuild top\n",
    "            x = GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "            x = BatchNormalization()(x)\n",
    "\n",
    "            top_dropout_rate = 0.2\n",
    "            x = Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "            outputs = Dense(class_num, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "            # Compile\n",
    "            model = tf.keras.Model(inputs, outputs, name=\"MobileNet\")\n",
    "            model.compile(optimizer=Adam(learning_rate=learning_rate), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    elif model_name == 'NASNetMobile':\n",
    "        \n",
    "        input_shape_TLmodel = '224'\n",
    "\n",
    "        if input_shape_TLmodel == '224':\n",
    "            learning_rate = 0.0001  # 0.0001\n",
    "            input_shape = (224, 224, 3)\n",
    "            inputs = Input(shape=input_shape)\n",
    "                \n",
    "            X_train2 = resize_to_224(X_train) \n",
    "            X_val2 = resize_to_224(X_val)\n",
    "        \n",
    "        batch_size = 2 \n",
    "        n_epochs = 50\n",
    "        \n",
    "        x = inputs\n",
    "        \n",
    "        with K.tf.device(gpu_no):\n",
    "            model = NASNetMobile(include_top=False, input_tensor=x, weights=\"imagenet\")\n",
    "            # Freeze the pretrained weights\n",
    "            model.trainable = False\n",
    "\n",
    "            # Rebuild top\n",
    "            x = GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "            x = BatchNormalization()(x)\n",
    "\n",
    "            top_dropout_rate = 0.2\n",
    "            x = Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "            outputs = Dense(class_num, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "            # Compile\n",
    "            model = tf.keras.Model(inputs, outputs, name=\"NASNetMobile\")\n",
    "            model.compile(optimizer=Adam(learning_rate=learning_rate), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "\n",
    "    elif model_name == 'ResNet50':\n",
    "        \n",
    "        input_shape_TLmodel = '224'\n",
    "                \n",
    "        if input_shape_TLmodel == '224':\n",
    "            learning_rate = 0.0001  # 0.0001\n",
    "            input_shape = (224, 224, 3)\n",
    "            inputs = Input(shape=input_shape)\n",
    "                \n",
    "            X_train2 = resize_to_224(X_train) \n",
    "            X_val2 = resize_to_224(X_val)\n",
    "        \n",
    "        batch_size = 2  \n",
    "        n_epochs = 50\n",
    "        \n",
    "        x = inputs\n",
    "        \n",
    "        with K.tf.device(gpu_no):\n",
    "            model = ResNet50(include_top=False, input_tensor=x, weights=\"imagenet\")\n",
    "            # Freeze the pretrained weights\n",
    "            model.trainable = False\n",
    "\n",
    "            # Rebuild top\n",
    "            x = GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "            x = BatchNormalization()(x)\n",
    "\n",
    "            top_dropout_rate = 0.2\n",
    "            x = Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "            outputs = Dense(class_num, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "            # Compile\n",
    "            model = tf.keras.Model(inputs, outputs, name=\"ResNet50\")\n",
    "            model.compile(optimizer=Adam(learning_rate=learning_rate), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    elif model_name == 'VGG16':\n",
    "        \n",
    "        input_shape_TLmodel = '224'\n",
    "        if input_shape_TLmodel == '224':\n",
    "            learning_rate = 0.0001  # 0.0001\n",
    "            input_shape = (224, 224, 3)\n",
    "            inputs = Input(shape=input_shape)\n",
    "                \n",
    "            X_train2 = resize_to_224(X_train) \n",
    "            X_val2 = resize_to_224(X_val)\n",
    "        \n",
    "        batch_size = 2  \n",
    "        n_epochs = 50\n",
    "        \n",
    "        x = inputs\n",
    "        \n",
    "        with K.tf.device(gpu_no):\n",
    "            model = VGG16(include_top=False, input_tensor=x, weights=\"imagenet\")\n",
    "            # Freeze the pretrained weights\n",
    "            model.trainable = False\n",
    "\n",
    "            # Rebuild top\n",
    "            x = GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "            x = BatchNormalization()(x)\n",
    "\n",
    "            top_dropout_rate = 0.2\n",
    "            x = Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "            outputs = Dense(class_num, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "            # Compile\n",
    "            model = tf.keras.Model(inputs, outputs, name=\"VGG16\")\n",
    "            model.compile(optimizer=Adam(learning_rate=learning_rate), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    print(X_train2.shape, X_val2.shape)\n",
    "    history1 = gen_cnn_model(gpu_no, model, model_path, val_fold[0], X_train2, y_train, X_val2, y_val, batch_size, n_epochs)\n",
    "    \n",
    "    # plot training and validation accuracy/loss values\n",
    "\n",
    "    history_list = list()\n",
    "    history_list.append(history1)\n",
    "\n",
    "    history_dict['val_fold='+str(val_f)] = history_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history_dict.keys())\n",
    "print(val_fold[0])\n",
    "\n",
    "for kk in [1,2,3,4,5]:\n",
    "    hist_list = history_dict['val_fold='+str(kk)]\n",
    "    print(len(hist_list))\n",
    "    print(hist_list[0].history.keys())\n",
    "    \n",
    "    if kk==1:\n",
    "        col = 'blue'\n",
    "    elif kk==2:\n",
    "        col = 'green'\n",
    "    elif kk==3:\n",
    "        col = 'red'\n",
    "    elif kk==4:\n",
    "        col = 'orange'\n",
    "    elif kk==5:\n",
    "        col = 'black'\n",
    "    \n",
    "    for ll, hist2 in enumerate(hist_list):\n",
    "        \n",
    "        plt.figure(num=1, figsize=(15, 8))\n",
    "        \n",
    "        plt.subplot(221)\n",
    "        plt.plot(hist2.history['loss'], color=col)\n",
    "        plt.title(f'Train loss')\n",
    "        plt.ylabel('Loss'); plt.xlabel('Epoch')\n",
    "        plt.ylim([0.0, 2.0])\n",
    "        plt.grid(True)\n",
    "        plt.legend(['fold 1', 'fold 2', 'fold 3', 'fold 4', 'fold 5'], loc='upper right')\n",
    "        \n",
    "        plt.subplot(222)\n",
    "        plt.plot(hist2.history['accuracy'], color=col)\n",
    "        plt.title(f'Train accuracy')\n",
    "        plt.ylabel('Accuracy'); plt.xlabel('Epoch')\n",
    "        plt.ylim([0.2, 1.0])\n",
    "        plt.grid(True)\n",
    "        plt.legend(['fold 1', 'fold 2', 'fold 3', 'fold 4', 'fold 5'], loc='upper left')\n",
    "        \n",
    "        plt.subplot(223)\n",
    "        plt.plot(hist2.history['val_loss'], color=col)\n",
    "        plt.title(f'Validation loss')\n",
    "        plt.ylabel('Loss'); plt.xlabel('Epoch')\n",
    "        plt.ylim([0.0, 2.0])\n",
    "        plt.grid(True)\n",
    "        plt.legend(['fold 1', 'fold 2', 'fold 3', 'fold 4', 'fold 5'], loc='upper right')\n",
    "        \n",
    "        plt.subplot(224)\n",
    "        plt.plot(hist2.history['val_accuracy'], color=col)\n",
    "        plt.title(f'Validation accuracy')\n",
    "        plt.ylabel('Accuracy'); plt.xlabel('Epoch')\n",
    "        plt.ylim([0.2, 1.0])\n",
    "        plt.grid(True)\n",
    "        plt.legend(['fold 1', 'fold 2', 'fold 3', 'fold 4', 'fold 5'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
